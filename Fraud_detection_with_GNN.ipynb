{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "Fraud detection with GNN",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gendeb/cloud-computing-specialization/blob/master/Fraud_detection_with_GNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "ealtman2019_credit_card_transactions_path = kagglehub.dataset_download('ealtman2019/credit-card-transactions')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "X5ANpBWk1sq6"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fraud Detection Using GNNs"
      ],
      "metadata": {
        "id": "f7ytR6yM1sq8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is fraud detection ?\n",
        "\n",
        "Fraud detection is the process of identifying and preventing unauthorized activity in organizations. It has become a major challenge for companies in industries such as banking, finance, retail, and e-commerce. Fraud can negatively impact an organization's financial performance and reputation, making it crucial for companies to prevent and predict suspicious activity.\n"
      ],
      "metadata": {
        "id": "zGAav1AV1sq8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Complex and evolving fraud patterns\n",
        "\n",
        "Fraudsters continually revise their strategies and devise ever-more-sophisticated methods to cheat the system, regularly involving intricate networks of transactions to prevent recognition. Traditional rule-based systems and matrix-based ML such as SVMs and XGBoost often just ponder the immediate edges of a deal (who transferred money to whom), usually omitting to notice fraudulent patterns with more complicated context. Rule-based systems furthermore need to be manually adjusted as fraud patterns shift and new scams arise.\n"
      ],
      "metadata": {
        "id": "eNz5JWTU1sq9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Label Quality\n",
        "\n",
        "The datasets for fraud detection are commonly unbalanced and incompletely labeled. In reality, only a tiny fraction of people plan to perpetrate fraud. Usually, domain specialists will label transactions as fraudulent or not, but they can't make certain that all fraud has been identified in the dataset.\n",
        "\n",
        "The large disparity between the number of labels and the amount of data available renders it hard to generate supervised models. Models trained on the accessible classifications could have a greater number of false negatives, while the imbalanced dataset could lead to an increase in false positives. Consequently, training Graph Neural Networks (GNNs) with different objectives and making use of their latent representations afterwards can be advantageous.\n"
      ],
      "metadata": {
        "id": "RH5s1Dja1sq9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model explainability\n",
        "\n",
        "Predicting if a transaction is fraudulent or not is inadequate for meeting the transparency standards of the banking sector. It is also essential to comprehend why certain deals are marked as deceitful. This explicability is critical for comprehending how fraud occurs, how to execute procedures to reduce fraud, and to make sure the process isn’t prejudiced. As a result, fraud detection models must be comprehensible and interpretable, which restricts the choices of models that investigators can apply."
      ],
      "metadata": {
        "id": "UlBLY7dP1sq9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graph approaches for fraud detection\n",
        "\n",
        "Transactions can be represented as a graph, with users as nodes and interactions between them as edges. Traditional feature-based algorithms such as XGBoost and DLRM analyze individual nodes or edges, while graph-based approaches take into account the local context and structure of the graph, including neighboring nodes and edges.\n",
        "\n",
        "In the traditional graph domain, there are various methods for making predictions based on graph structure, such as statistical approaches that aggregate features from adjacent nodes or edges. Algorithms like the [Louvain method](https://en.wikipedia.org/wiki/Louvain_method) and [InfoMap](https://towardsdatascience.com/infomap-algorithm-9b68b7e8b86) can identify communities and clusters of users on the graph. However, these methods lack the expressivity to fully consider the graph in its original format.\n",
        "\n",
        "Graph neural networks (GNNs) offer a solution by representing local structural and feature context natively within the model. Through aggregation and message passing, information from both edges and nodes is propagated to neighboring nodes. Multiple layers of graph convolution result in a node's state containing information from nodes multiple layers away, effectively allowing the GNN to have a \"receptive field\" of nodes or edges multiple jumps away from the node or edge in question.\n",
        "\n",
        "For fraud detection, GNNs can account for complex or longer chains of transactions that fraudsters use for obfuscation. Additionally, changing patterns can be addressed by retraining the model iteratively."
      ],
      "metadata": {
        "id": "2wjR7JhY1sq9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ML for graph\n",
        "\n",
        "These are the general steps of ML on Graph, depending on the task, the methods used in each step may change and not all the steps may be needed.\n",
        "\n",
        "1. Graph Representation: The first step in applying machine learning techniques to graphs is to represent the graph in a format that can be input into a machine learning model. This can be done using various graph representations such as adjacency matrices, adjacency lists, and edge lists.\n",
        "\n",
        "2. Feature Extraction: Once the graph is represented, the next step is to extract features from the graph that can be used as input to a machine learning model. These features can include things like node degree, centrality measures, and graph traversal patterns.\n",
        "\n",
        "3. Dimensionality Reduction: As the number of nodes and edges in a graph can be large, it is often necessary to reduce the dimensionality of the graph representation before applying machine learning techniques. This can be done using techniques like principal component analysis (PCA) and t-SNE.\n",
        "\n",
        "4. Model Selection: After the graph is represented and features have been extracted, the next step is to select a machine learning model that can be applied to the graph data. Common models used for graph data include decision trees, random forests, and neural networks.\n",
        "\n",
        "5. Training and Evaluation: Once the model is selected, it is trained on the graph data using a labeled training dataset. The model is then evaluated on a separate test dataset to assess its performance.\n",
        "\n",
        "6. Predictions: After the model is trained, it can be used to make predictions on new graph data. For example, it can be used to predict the likelihood of a node in a graph being in a certain class or to predict the likelihood of a link between two nodes."
      ],
      "metadata": {
        "id": "1eoL0bAX1sq-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "The IBM credit card transaction dataset is a publicly available dataset that contains information about credit card transactions. It is often used for research and testing of fraud detection models. The dataset includes a variety of features such as the amount of the transaction, the type of card used, and the location of the transaction. It also includes a label indicating whether or not the transaction was fraudulent. The dataset is designed to be representative of real-world transactions and therefore contains a certain level of class imbalance, with a higher number of non-fraudulent transactions than fraudulent transactions. The dataset is provided by IBM and the data is simulated, but it is not specified the exact process of data simulation. It is important to note that the data is not real and it is not linked to any real customer or financial institution.\n",
        "\n",
        "The data set contains:\n",
        "* 24 million unique transactions\n",
        "* 6,000 unique merchants\n",
        "* 100,000 unique cards\n",
        "* 30,000 fraudulent samples (0.1% of total transactions)\n",
        "\n",
        "**Where to find the data**\n",
        "* If you are willing to use the data locally you can download it from this [link](https://ibm.ent.box.com/v/tabformer-data)\n",
        "* In our case we will use Kaggle to create our GNN model so we are using the dataset on kaggle, here's the [link](https://www.kaggle.com/datasets/ealtman2019/credit-card-transactions)"
      ],
      "metadata": {
        "id": "nRuf99gx1sq-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Necessary imports"
      ],
      "metadata": {
        "id": "B029rG971sq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import networkx as nx\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-16T21:08:15.6821Z",
          "iopub.execute_input": "2023-01-16T21:08:15.682511Z",
          "iopub.status.idle": "2023-01-16T21:08:15.689776Z",
          "shell.execute_reply.started": "2023-01-16T21:08:15.682477Z",
          "shell.execute_reply": "2023-01-16T21:08:15.688076Z"
        },
        "trusted": true,
        "id": "_0o74y_j1sq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprosessing\n",
        "\n",
        "Preprocessing tabular data before creating a graph is important because it ensures that the data is in a format that can be easily converted into a graph structure. Tabular data, such as a CSV file, typically contains rows and columns of information, with each row representing a single record and each column representing a specific feature or attribute. Before creating a graph, it is essential to clean and transform the data so that it is consistent and in a format that can be easily mapped to a graph structure. This may include tasks such as filling in missing values, converting data types, and removing duplicates.\n",
        "\n",
        "Additionally, preprocessing tabular data can also help to improve the performance and accuracy of graph-based algorithms by reducing noise and irrelevant information in the data. This can be achieved by removing irrelevant features, normalizing numerical data, and encoding categorical data. Preprocessing can also help to balance the class distribution in case of imbalanced data, which is a common problem in fraud detection datasets.\n",
        "\n",
        "**Note:**\n",
        "\n",
        "For hardware limitations we will only take 100.000 samples of our data."
      ],
      "metadata": {
        "id": "DPP0_Cru1sq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the tabular dataset\n",
        "df = pd.read_csv(\"/kaggle/input/credit-card-transactions/credit_card_transactions-ibm_v2.csv\").sample(n=100000, random_state=42)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-16T21:02:57.755879Z",
          "iopub.execute_input": "2023-01-16T21:02:57.756542Z",
          "iopub.status.idle": "2023-01-16T21:04:23.668499Z",
          "shell.execute_reply.started": "2023-01-16T21:02:57.756503Z",
          "shell.execute_reply": "2023-01-16T21:04:23.667008Z"
        },
        "trusted": true,
        "id": "-W-VxaVm1sq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-16T21:04:23.671699Z",
          "iopub.execute_input": "2023-01-16T21:04:23.672324Z",
          "iopub.status.idle": "2023-01-16T21:04:23.770159Z",
          "shell.execute_reply.started": "2023-01-16T21:04:23.672275Z",
          "shell.execute_reply": "2023-01-16T21:04:23.768565Z"
        },
        "trusted": true,
        "id": "m45ii27j1sq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We need to make sure that the samples we extracted have some rows where fraud is True\n",
        "df [df['Is Fraud?'] == 'Yes'].shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-16T21:04:23.771853Z",
          "iopub.execute_input": "2023-01-16T21:04:23.772609Z",
          "iopub.status.idle": "2023-01-16T21:04:23.792769Z",
          "shell.execute_reply.started": "2023-01-16T21:04:23.772521Z",
          "shell.execute_reply": "2023-01-16T21:04:23.790768Z"
        },
        "trusted": true,
        "id": "L2qIosHm1sq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "percent_missing=(df.isnull().sum()*100/df.shape[0]).sort_values(ascending=True)\n",
        "plt.title(\"Missing Value Analysis\")\n",
        "plt.xlabel(\"Features\")\n",
        "plt.ylabel(\"% of missing values\")\n",
        "plt.bar(percent_missing.sort_values(ascending=False).index,percent_missing.sort_values(ascending=False),color=(0.1, 0.1, 0.1, 0.1),edgecolor='blue')\n",
        "plt.xticks(rotation=90)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-16T21:04:23.796135Z",
          "iopub.execute_input": "2023-01-16T21:04:23.797075Z",
          "iopub.status.idle": "2023-01-16T21:04:24.225588Z",
          "shell.execute_reply.started": "2023-01-16T21:04:23.797018Z",
          "shell.execute_reply": "2023-01-16T21:04:24.223789Z"
        },
        "trusted": true,
        "id": "bxlZboJm1sq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The card_id is defined as one card by one user. A specific user can have multiple cards, which would correspond to multiple different card_ids for this graph.\n",
        "For this reason we will create a new column which is the concatenation of the column User and the Column Card"
      ],
      "metadata": {
        "id": "3QZE6iZd1sq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"card_id\"] = df[\"User\"].astype(str) + \"_\" + df[\"Card\"].astype(str)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-16T21:04:24.227364Z",
          "iopub.execute_input": "2023-01-16T21:04:24.227819Z",
          "iopub.status.idle": "2023-01-16T21:04:24.381702Z",
          "shell.execute_reply.started": "2023-01-16T21:04:24.227781Z",
          "shell.execute_reply": "2023-01-16T21:04:24.380181Z"
        },
        "trusted": true,
        "id": "-PN9cS1R1sq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.Amount.head(5)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-16T21:04:24.383425Z",
          "iopub.execute_input": "2023-01-16T21:04:24.384304Z",
          "iopub.status.idle": "2023-01-16T21:04:24.393573Z",
          "shell.execute_reply.started": "2023-01-16T21:04:24.384265Z",
          "shell.execute_reply": "2023-01-16T21:04:24.391625Z"
        },
        "trusted": true,
        "id": "PiEN3v541sq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We need to strip the ‘$’ from the Amount to cast as a float\n",
        "df[\"Amount\"]=df[\"Amount\"].str.replace(\"$\",\"\").astype(float)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-16T21:04:24.395249Z",
          "iopub.execute_input": "2023-01-16T21:04:24.396354Z",
          "iopub.status.idle": "2023-01-16T21:04:24.574714Z",
          "shell.execute_reply.started": "2023-01-16T21:04:24.396307Z",
          "shell.execute_reply": "2023-01-16T21:04:24.573724Z"
        },
        "trusted": true,
        "id": "rlBKTLec1sq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# time can't be casted to int so so opted to extract the hour and minute\n",
        "df[\"Hour\"] = df[\"Time\"].str [0:2]\n",
        "df[\"Minute\"] = df[\"Time\"].str [3:5]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-16T21:04:24.57579Z",
          "iopub.execute_input": "2023-01-16T21:04:24.577077Z",
          "iopub.status.idle": "2023-01-16T21:04:24.745287Z",
          "shell.execute_reply.started": "2023-01-16T21:04:24.5769Z",
          "shell.execute_reply": "2023-01-16T21:04:24.743972Z"
        },
        "trusted": true,
        "id": "b8PZv9X81sq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.Hour"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-16T21:04:24.747153Z",
          "iopub.execute_input": "2023-01-16T21:04:24.747613Z",
          "iopub.status.idle": "2023-01-16T21:04:24.758257Z",
          "shell.execute_reply.started": "2023-01-16T21:04:24.747539Z",
          "shell.execute_reply": "2023-01-16T21:04:24.756259Z"
        },
        "trusted": true,
        "id": "5wspuiqH1sq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.Minute"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-16T21:04:24.764947Z",
          "iopub.execute_input": "2023-01-16T21:04:24.765446Z",
          "iopub.status.idle": "2023-01-16T21:04:24.921271Z",
          "shell.execute_reply.started": "2023-01-16T21:04:24.765408Z",
          "shell.execute_reply": "2023-01-16T21:04:24.919646Z"
        },
        "trusted": true,
        "id": "YDo7wQ_A1sq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop([\"Time\",\"User\",\"Card\"],axis=1)\n",
        "df.info()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-16T21:04:24.923441Z",
          "iopub.execute_input": "2023-01-16T21:04:24.923964Z",
          "iopub.status.idle": "2023-01-16T21:04:25.062506Z",
          "shell.execute_reply.started": "2023-01-16T21:04:24.923909Z",
          "shell.execute_reply": "2023-01-16T21:04:25.060936Z"
        },
        "trusted": true,
        "id": "U6N3Iiq_1sq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Errors?\"].unique()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-16T21:04:25.064389Z",
          "iopub.execute_input": "2023-01-16T21:04:25.064933Z",
          "iopub.status.idle": "2023-01-16T21:04:25.079731Z",
          "shell.execute_reply.started": "2023-01-16T21:04:25.064892Z",
          "shell.execute_reply": "2023-01-16T21:04:25.07796Z"
        },
        "trusted": true,
        "id": "1QIBvJbJ1sq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Errors?\"]= df[\"Errors?\"].fillna(\"No error\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-16T21:04:25.081141Z",
          "iopub.execute_input": "2023-01-16T21:04:25.081579Z",
          "iopub.status.idle": "2023-01-16T21:04:25.098267Z",
          "shell.execute_reply.started": "2023-01-16T21:04:25.081535Z",
          "shell.execute_reply": "2023-01-16T21:04:25.096603Z"
        },
        "trusted": true,
        "id": "Gsqr_vqn1sq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The two columns Zip and Merchant state contains missing values which can affect our graph. Moreover these information can be extracted from the column Merchant City so we will drop them."
      ],
      "metadata": {
        "id": "Aq_Py3W-1sq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(columns=[\"Merchant State\",\"Zip\"],axis=1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-16T21:04:25.100132Z",
          "iopub.execute_input": "2023-01-16T21:04:25.1006Z",
          "iopub.status.idle": "2023-01-16T21:04:25.129311Z",
          "shell.execute_reply.started": "2023-01-16T21:04:25.100563Z",
          "shell.execute_reply": "2023-01-16T21:04:25.12808Z"
        },
        "trusted": true,
        "id": "mhaCCcbb1sq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# change the is fraud column to binary\n",
        "df[\"Is Fraud?\"] = df[\"Is Fraud?\"].apply(lambda x: 1 if x == 'Yes' else 0)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-16T21:04:25.131026Z",
          "iopub.execute_input": "2023-01-16T21:04:25.131409Z",
          "iopub.status.idle": "2023-01-16T21:04:25.193513Z",
          "shell.execute_reply.started": "2023-01-16T21:04:25.131375Z",
          "shell.execute_reply": "2023-01-16T21:04:25.19207Z"
        },
        "trusted": true,
        "id": "hQ3o4ALv1srA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Merchant City\"]=LabelEncoder().fit_transform(df[\"Merchant City\"])\n",
        "df[\"Use Chip\"]=LabelEncoder().fit_transform(df[\"Use Chip\"])\n",
        "df[\"Errors?\"]=LabelEncoder().fit_transform(df[\"Errors?\"])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-16T21:04:25.195485Z",
          "iopub.execute_input": "2023-01-16T21:04:25.195994Z",
          "iopub.status.idle": "2023-01-16T21:04:25.339333Z",
          "shell.execute_reply.started": "2023-01-16T21:04:25.195927Z",
          "shell.execute_reply": "2023-01-16T21:04:25.338041Z"
        },
        "trusted": true,
        "id": "kFwwsUHI1srA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Errors?\"].unique()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-16T21:04:25.341182Z",
          "iopub.execute_input": "2023-01-16T21:04:25.341534Z",
          "iopub.status.idle": "2023-01-16T21:04:25.35339Z",
          "shell.execute_reply.started": "2023-01-16T21:04:25.341502Z",
          "shell.execute_reply": "2023-01-16T21:04:25.35193Z"
        },
        "trusted": true,
        "id": "WMgE2Zzj1srA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-16T21:04:25.355142Z",
          "iopub.execute_input": "2023-01-16T21:04:25.355589Z",
          "iopub.status.idle": "2023-01-16T21:04:25.391559Z",
          "shell.execute_reply.started": "2023-01-16T21:04:25.355554Z",
          "shell.execute_reply": "2023-01-16T21:04:25.38995Z"
        },
        "trusted": true,
        "id": "2CicS6Rs1srA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GNN for fraud detection:\n",
        "Creating a multigraph for fraud detection using transaction data and applying a Graph Neural Network (GNN) on the edge list can be done in the following steps:\n",
        "\n",
        "1. Prepare the transaction data: Collect and organize the transaction data into a format that can be used to create the edges of the multigraph. For example, each transaction could be represented as a tuple (node1, node2, attributes), where node1 and node2 represent the sender and receiver of the transaction, and attributes is a dictionary containing properties such as the amount, timestamp, and transaction type.\n",
        "\n",
        "2. Create the multigraph: Use the transaction data to create a multigraph using the NetworkX library. The add_edge() method can be used to add edges to the multigraph, where each edge represents a transaction.\n",
        "\n",
        "3. Extract the edges list and their features: Use the edges() method of the multigraph to extract the edges list and their features, which will be used as input to the GNN.\n",
        "\n",
        "4. Apply a GNN on the edge list: Use a GNN library such as PyTorch Geometric, Deep Graph Library (DGL) or Spektral to apply a GNN on the edge list. The GNN will learn representations of the edges in the multigraph and use them to classify the edges as fraudulent or non-fraudulent.\n",
        "\n",
        "5. Evaluation: To evaluate the performance of the GNN, you can split the data into train and test sets, and use the test set to evaluate the accuracy, precision, recall, and F1-score of the model."
      ],
      "metadata": {
        "id": "uErzA2Fo1srA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Graph construction\n",
        "\n",
        "When constructing a graph with transaction edges between card_id and merchant_name, the first step is to identify the nodes in the graph. In this case, the card_id and merchant_name represent the nodes in the graph. Each card_id represents a unique credit card and each merchant_name represents a unique merchant. These nodes can be created by extracting the card_id and merchant_name information from the tabular data and storing them in separate lists.\n",
        "\n",
        "Once the nodes have been identified, the next step is to create edges between them. These edges represent the transactions that have taken place between a card_id and a merchant_name. To create the edges, a list of transactions is created and for each transaction, an edge is created between the card_id and merchant_name.\n"
      ],
      "metadata": {
        "id": "nTWHVNOk1srA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Method 1"
      ],
      "metadata": {
        "id": "YVM9yLdH1srA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are creating an empty multigraph object called G using the nx.MultiGraph() function from the NetworkX library. Then we add nodes to the graph for each unique card_id and merchant_name from the dataframe df.\n",
        "\n",
        "The add_nodes_from method is used to add nodes to the graph, it takes an iterable as input and creates a node for each element in the iterable. The df[\"card_id\"].unique() will return a list of unique card_ids in the dataframe, and the df[\"Merchant Name\"].unique will return a list of all the merchant names in the dataframe.\n",
        "\n",
        "The type attribute is added to each node, it is used to differentiate between card_id and merchant_name nodes. This will help later on when we want to analyze the graph.\n",
        "\n",
        "**Why did we use a multigraph and not graph?**\n",
        "\n",
        "The same user (card_id) can buy from the same merchant (Merchant Name) multiple times, so we can have multiple edges between the user and the merchant and for this reason we used multigraph instead of graph\n",
        "\n",
        "  ![image.png](attachment:7787e1f7-3e13-44c0-9ddb-2e4d67d20c13.png)\n"
      ],
      "metadata": {
        "id": "rYoSy9OR1srA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an empty graph\n",
        "G = nx.MultiGraph()\n",
        "\n",
        "# Add nodes to the graph for each unique card_id, merchant_name\n",
        "G.add_nodes_from(df[\"card_id\"].unique(), type='card_id')\n",
        "G.add_nodes_from(df[\"Merchant Name\"].unique(), type='merchant_name')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-16T21:04:59.09978Z",
          "iopub.execute_input": "2023-01-16T21:04:59.101133Z",
          "iopub.status.idle": "2023-01-16T21:04:59.147377Z",
          "shell.execute_reply.started": "2023-01-16T21:04:59.101074Z",
          "shell.execute_reply": "2023-01-16T21:04:59.146367Z"
        },
        "trusted": true,
        "id": "-eE3393z1srA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code below adding edges and properties to the edges of a graph. The code iterates through each row of the dataframe, df, and creates a variable for each property then assign it to the edge between the card_id and merchant_name of that row."
      ],
      "metadata": {
        "id": "pl0H8o-y1srA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add edges and properties to the edges\n",
        "for _, row in df.iterrows():\n",
        "    # Create a variable for each properties for each edge\n",
        "\n",
        "        year = row[\"Year\"],\n",
        "        month = row[\"Month\"],\n",
        "        day = row[\"Day\"],\n",
        "        hour = row[\"Hour\"],\n",
        "        minute =row[\"Minute\"],\n",
        "        amount = row[\"Amount\"],\n",
        "        use_chip =  row[\"Use Chip\"],\n",
        "        merchant_city = row[\"Merchant City\"],\n",
        "        errors =  row[\"Errors?\"],\n",
        "        mcc = row['MCC']\n",
        "\n",
        "\n",
        "        G.add_edge(row['card_id'], row['Merchant Name'], year = year , month = month , day = day ,\n",
        "              hour = hour , minute = minute , amount = amount , use_chip = use_chip ,\n",
        "              merchant_city = merchant_city , errors = errors , mcc = mcc)\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-16T21:04:59.149502Z",
          "iopub.execute_input": "2023-01-16T21:04:59.150566Z",
          "iopub.status.idle": "2023-01-16T21:05:11.197027Z",
          "shell.execute_reply.started": "2023-01-16T21:04:59.150526Z",
          "shell.execute_reply": "2023-01-16T21:05:11.195877Z"
        },
        "trusted": true,
        "id": "1fgX5ggq1srA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the number of nodes and edges in the graph\n",
        "num_nodes = G.number_of_nodes()\n",
        "num_edges = G.number_of_edges()\n",
        "\n",
        "# Print the number of nodes and edges\n",
        "print(\"Number of nodes:\", num_nodes)\n",
        "print(\"Number of edges:\", num_edges)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-16T21:05:11.198964Z",
          "iopub.execute_input": "2023-01-16T21:05:11.200279Z",
          "iopub.status.idle": "2023-01-16T21:05:11.260184Z",
          "shell.execute_reply.started": "2023-01-16T21:05:11.200228Z",
          "shell.execute_reply": "2023-01-16T21:05:11.259136Z"
        },
        "trusted": true,
        "id": "zzPdxAGj1srE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the graph to an adjacency matrix\n",
        "adj_matrix = nx.adjacency_matrix(G).todense()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-16T21:05:56.99637Z",
          "iopub.execute_input": "2023-01-16T21:05:56.996797Z",
          "iopub.status.idle": "2023-01-16T21:05:57.823056Z",
          "shell.execute_reply.started": "2023-01-16T21:05:56.996759Z",
          "shell.execute_reply": "2023-01-16T21:05:57.821824Z"
        },
        "trusted": true,
        "id": "k0rx1roO1srE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adj_matrix.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-16T21:05:57.825182Z",
          "iopub.execute_input": "2023-01-16T21:05:57.825732Z",
          "iopub.status.idle": "2023-01-16T21:05:57.833229Z",
          "shell.execute_reply.started": "2023-01-16T21:05:57.825696Z",
          "shell.execute_reply": "2023-01-16T21:05:57.83179Z"
        },
        "trusted": true,
        "id": "dzMHeths1srE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will retrieve the properties of a small sample of **nodes** in our graph (G) and print their properties."
      ],
      "metadata": {
        "id": "WY98SGOy1srE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a small sample of the nodes in the graph\n",
        "sample_nodes = list(G.nodes())[:10]\n",
        "\n",
        "# Retrieve the properties of the sample nodes\n",
        "node_properties = nx.get_node_attributes(G, 'type')\n",
        "\n",
        "# Print the properties of the sample nodes\n",
        "for node in sample_nodes:\n",
        "    print(f\"Node: {node}, Properties: {node_properties[node]}\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-16T21:05:57.835126Z",
          "iopub.execute_input": "2023-01-16T21:05:57.836497Z",
          "iopub.status.idle": "2023-01-16T21:05:57.860033Z",
          "shell.execute_reply.started": "2023-01-16T21:05:57.836446Z",
          "shell.execute_reply": "2023-01-16T21:05:57.858785Z"
        },
        "trusted": true,
        "id": "Xfv9Xzd91srE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_size = 5\n",
        "for i, edge in enumerate(G.edges()):\n",
        "    print(G.get_edge_data(*edge))\n",
        "    if i >= sample_size - 1:\n",
        "        break"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-16T21:05:57.862402Z",
          "iopub.execute_input": "2023-01-16T21:05:57.862762Z",
          "iopub.status.idle": "2023-01-16T21:05:57.870056Z",
          "shell.execute_reply.started": "2023-01-16T21:05:57.86273Z",
          "shell.execute_reply": "2023-01-16T21:05:57.868163Z"
        },
        "trusted": true,
        "id": "c7vBLvg01srE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will retrieve the properties of a small sample of **edges** in our graph (G) and print their properties."
      ],
      "metadata": {
        "id": "hVx1fC8X1srE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve the properties errors of all the edges\n",
        "edge_properties = nx.get_edge_attributes(G, 'errors')\n",
        "\n",
        "# Count the number of edges by property value\n",
        "edge_count_by_property = Counter(edge_properties.values())\n",
        "\n",
        "# Print the count of edges by property value\n",
        "for property_value, count in edge_count_by_property.items():\n",
        "    print(f\"Property value: {property_value}, Count: {count}\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-16T21:05:57.871964Z",
          "iopub.execute_input": "2023-01-16T21:05:57.872391Z",
          "iopub.status.idle": "2023-01-16T21:05:58.134277Z",
          "shell.execute_reply.started": "2023-01-16T21:05:57.872358Z",
          "shell.execute_reply": "2023-01-16T21:05:58.133092Z"
        },
        "trusted": true,
        "id": "iwEiWCD01srE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the data for input into the model\n",
        "edge_list = list(G.edges(data=True))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-16T21:05:58.136192Z",
          "iopub.execute_input": "2023-01-16T21:05:58.136545Z",
          "iopub.status.idle": "2023-01-16T21:05:58.387685Z",
          "shell.execute_reply.started": "2023-01-16T21:05:58.136505Z",
          "shell.execute_reply": "2023-01-16T21:05:58.386486Z"
        },
        "trusted": true,
        "id": "OCxBfVxB1srE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(edge_list[i][2].values())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-16T21:05:58.389431Z",
          "iopub.execute_input": "2023-01-16T21:05:58.390302Z",
          "iopub.status.idle": "2023-01-16T21:05:58.398607Z",
          "shell.execute_reply.started": "2023-01-16T21:05:58.390255Z",
          "shell.execute_reply": "2023-01-16T21:05:58.397775Z"
        },
        "trusted": true,
        "id": "YuXXzMF01srE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define a PyTorch neural network model called \"FraudGNN\" which is a type of Graph Neural Network. The model is a simple feedforward neural network with two fully connected (Linear) layers. The first layer has input_dim number of input units and hidden_dim number of output units, while the second layer has hidden_dim number of input units and 1 output unit.\n",
        "The forward function of the model applies the linear layers to the input tensor \"x\" and applies a ReLU activation function to the output of the first linear layer.\n",
        "\n",
        "We also prepare data for input into the model. We define the variable \"edge_list\" which is a list of edges and their associated data in a graph G. Then we create an empty list called \"x\" and iterates over each edge in the edge_list. For each edge, it extracts the values of the edge data, converts them to floats if needed, and append them to the list \"x\". Finally, we convert the list \"x\" to a PyTorch tensor with float datatype, which is ready to be input into the FraudGNN model."
      ],
      "metadata": {
        "id": "JxmBfs9P1srF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FraudGNN(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super(FraudGNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x.squeeze(-1)\n",
        "\n",
        "# Prepare the data for input into the model\n",
        "edge_list = list(G.edges(data=True))\n",
        "x = []\n",
        "for edge in edge_list:\n",
        "    edge_values = list(edge[2].values())\n",
        "    edge_values = [float(i[0]) if type(i) == tuple and type(i[0]) == str else i[0] if type(i) == tuple else i for i in edge_values]\n",
        "    x.append(edge_values)\n",
        "x = torch.tensor(x, dtype=torch.float)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-16T21:22:49.199098Z",
          "iopub.execute_input": "2023-01-16T21:22:49.199526Z",
          "iopub.status.idle": "2023-01-16T21:22:50.703386Z",
          "shell.execute_reply.started": "2023-01-16T21:22:49.199494Z",
          "shell.execute_reply": "2023-01-16T21:22:50.70221Z"
        },
        "trusted": true,
        "id": "GmiUFXyX1srF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target = torch.tensor(df['Is Fraud?'].values, dtype=torch.float)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-16T21:22:52.213847Z",
          "iopub.execute_input": "2023-01-16T21:22:52.214265Z",
          "iopub.status.idle": "2023-01-16T21:22:52.220759Z",
          "shell.execute_reply.started": "2023-01-16T21:22:52.214232Z",
          "shell.execute_reply": "2023-01-16T21:22:52.219048Z"
        },
        "trusted": true,
        "id": "LFPZeOmR1srF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "input_dim = len(x[0])\n",
        "hidden_dim = 16\n",
        "model = FraudGNN(input_dim, hidden_dim)\n",
        "num_epochs=201\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-16T21:22:55.479572Z",
          "iopub.execute_input": "2023-01-16T21:22:55.479953Z",
          "iopub.status.idle": "2023-01-16T21:22:55.486403Z",
          "shell.execute_reply.started": "2023-01-16T21:22:55.479922Z",
          "shell.execute_reply": "2023-01-16T21:22:55.485519Z"
        },
        "trusted": true,
        "id": "zNrj_qWG1srF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "for i in range(num_epochs):\n",
        "    # Forward pass\n",
        "    output = model(x)\n",
        "    # Compute the loss\n",
        "    loss = criterion(output, target)\n",
        "    if i % 20 == 0:\n",
        "        print(f'Epoch: {i}, Loss: {loss.item()}')\n",
        "    # Zero the gradients\n",
        "    optimizer.zero_grad()\n",
        "    # Perform backpropagation\n",
        "    loss.backward()\n",
        "    # Update the parameters\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-16T21:22:58.151218Z",
          "iopub.execute_input": "2023-01-16T21:22:58.153084Z",
          "iopub.status.idle": "2023-01-16T21:23:02.723745Z",
          "shell.execute_reply.started": "2023-01-16T21:22:58.153021Z",
          "shell.execute_reply": "2023-01-16T21:23:02.722551Z"
        },
        "trusted": true,
        "id": "HyGj87dM1srF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Method 2"
      ],
      "metadata": {
        "id": "xpXeYkxb1srF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this part we will base our work on the [paper](https://www.sciencedirect.com/science/article/abs/pii/S0957417421017449) **Inductive Graph Representation Learning for fraud detection** written by RafaëlVan Belle, Charles Van Damme, Hendrik Tytgat and JochenDe Weerdt.\n",
        "\n",
        "Charles has created a python library with the name of inductiveGRL for the experimental setup of their paper.\n",
        "\n",
        "Library overview :\n",
        "\n",
        "1. Transaction Data\n",
        "Any dataset that can be transformed into a graph can be used in our experimental setup. For our research, we used a real-life dataset to construct credit card transaction networks containing millions of transactions. This dataset includes information on the following features: anonymized identification of clients and merchants, merchant category code, country, monetary amount, time, acceptance, and fraud label. This real-life dataset is highly imbalanced and contains only 0.65% fraudulent transactions. Note that the demo data in this repository is artificaly generated for demonstration purposes. The Timeframes component derives the different timeframes for a rolling window setup given a step and window size.\n",
        "\n",
        "2. Graph Construction\n",
        "The GraphConstruction component constructs the graphs that will be used by graph representation learners (e.g. FI-GRL and GraphSAGE) to learn node embeddings. We designed the credit card transaction networks as heterogeneous tripartite graphs containing client, merchant and transaction nodes. Because of this tripartite setup, representations can be learned for the transaction nodes. Only the transaction nodes are configured with node features.\n",
        "\n",
        "3. GraphSAGE\n",
        "The HinSAGE code deploys a supervised, heterogeneous implementation of the GraphSAGE framework called HinSAGE, to learn embeddings of the transaction nodes in the aforementioned graphs.\n",
        "\n",
        "4. FI-GRL\n",
        "The FIGRL code learns embeddings of the transaction nodes in the aforementioned graphs using the Fast Inductive Graph Representation Learning Framework. We call the Matlab implementation of FI-GRL from our Jupyter notebooks, which requires an appropriate installation of matlab.engine in the same folder as the notebooks. If you wish to run FI-GRL from Python, please run the following command in Matlab:\n",
        "\n",
        "cd (fullfile(matlabroot,'extern','engines','python'))\n",
        "system('python setup.py install')\n",
        "\n",
        "This will generate a folder in matlabroot\\extern\\engines\\python\\build\\lib called 'matlab' please copy this folder and place it on the same location as the notebook from which you want to call matlab.engine. If you don't know your matlab root, running 'matlabroot' in Matlab will return the appropriate path.\n",
        "\n",
        "5. Classifier\n",
        "The penultimate component in our pipeline uses the transaction node embeddings to classify the transaction nodes as fraudulent or legitimate. We chose to rely on XGBoost as a classification model, but other classifiers can easily be implemented.\n",
        "\n",
        "6. Evaluation\n",
        "The Evaluation component contains functions for the Lift score, Lift curve and precision-recall curve. We focused on these evaluation metrics given the highly imbalanced nature of our dataset. However, this code can easily be extended to contain other evaluation metrics such as ROC plots."
      ],
      "metadata": {
        "id": "fjCWV4Bx1srF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#library installation\n",
        "!pip install inductiveGRL"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-16T21:08:59.215951Z",
          "iopub.execute_input": "2023-01-16T21:08:59.216406Z",
          "iopub.status.idle": "2023-01-16T21:09:41.666384Z",
          "shell.execute_reply.started": "2023-01-16T21:08:59.216369Z",
          "shell.execute_reply": "2023-01-16T21:09:41.664133Z"
        },
        "trusted": true,
        "id": "PjLmFW3B1srF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# necessary imports of this part\n",
        "from inductiveGRL.graphconstruction import GraphConstruction\n",
        "from inductiveGRL.hinsage import HinSAGE_Representation_Learner"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-16T21:09:41.671665Z",
          "iopub.execute_input": "2023-01-16T21:09:41.672131Z",
          "iopub.status.idle": "2023-01-16T21:09:47.765858Z",
          "shell.execute_reply.started": "2023-01-16T21:09:41.672086Z",
          "shell.execute_reply": "2023-01-16T21:09:47.764945Z"
        },
        "trusted": true,
        "id": "bQe3CONp1srF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Global parameters:\n",
        "embedding_size = 64\n",
        "add_additional_data = True"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-16T21:09:47.76982Z",
          "iopub.execute_input": "2023-01-16T21:09:47.771863Z",
          "iopub.status.idle": "2023-01-16T21:09:47.780728Z",
          "shell.execute_reply.started": "2023-01-16T21:09:47.771823Z",
          "shell.execute_reply": "2023-01-16T21:09:47.778742Z"
        },
        "trusted": true,
        "id": "ZYJmJqYk1srF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will split our data 70% to train_data and 30% for inductive data that will be used to test the model's ability to generalize to new, unseen data.\n",
        "\n",
        "First we calculate the cutoff point for the split using the formula \"cutoff = round(0.7*len(df))\" where 0.7 represents 70% of the data, and len(df) is the total number of rows in the dataframe. The round function is used to round the cutoff point to the nearest whole number.\n",
        "\n",
        "Second we assign the first \"cutoff\" rows of the dataframe to the variable \"train_data\" by calling the head() function on the dataframe and passing the cutoff point as an argument. These rows will be used as the training data.\n",
        "\n",
        "Last we assign the remaining rows of the dataframe (the rows after the cutoff point) to the variable \"inductive_data\" by calling the tail() function on the dataframe and passing the number of remaining rows (len(df) - cutoff) as an argument. These rows will be used as the inductive data."
      ],
      "metadata": {
        "id": "xGoec5sF1srF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we will take 70% of our dataset as traindata\n",
        "cutoff = round(0.7*len(df))\n",
        "train_data = df.head(cutoff)\n",
        "inductive_data = df.tail(len(df)-cutoff)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-16T21:09:47.784038Z",
          "iopub.execute_input": "2023-01-16T21:09:47.784848Z",
          "iopub.status.idle": "2023-01-16T21:09:47.801896Z",
          "shell.execute_reply.started": "2023-01-16T21:09:47.78479Z",
          "shell.execute_reply": "2023-01-16T21:09:47.800276Z"
        },
        "trusted": true,
        "id": "ikUsqO_91srF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('The distribution of fraud for the train data is:\\n', train_data['Is Fraud?'].value_counts())\n",
        "print('The distribution of fraud for the inductive data is:\\n', inductive_data['Is Fraud?'].value_counts())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-16T21:09:47.803762Z",
          "iopub.execute_input": "2023-01-16T21:09:47.804188Z",
          "iopub.status.idle": "2023-01-16T21:09:47.818779Z",
          "shell.execute_reply.started": "2023-01-16T21:09:47.804148Z",
          "shell.execute_reply": "2023-01-16T21:09:47.817788Z"
        },
        "trusted": true,
        "id": "N9-Yk1eW1srF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Graphe construction"
      ],
      "metadata": {
        "id": "DVSEHEV71srF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will create a graph from a train_data using the GraphConstruction class. First we create the dataframes for the node data, second we define the nodes and edges, third  we create a dictionary of features, and finally we create a graph object, and calls the get_stellargraph() method to get the StellarGraph object."
      ],
      "metadata": {
        "id": "Dcm_WEvO1srF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transaction_node_data = train_data.drop(\"card_id\", axis=1).drop(\"Merchant Name\", axis=1).drop('Is Fraud?', axis=1)\n",
        "client_node_data = pd.DataFrame([1]*len(train_data[\"card_id\"].unique())).set_index(train_data[\"card_id\"].unique())\n",
        "merchant_node_data = pd.DataFrame([1]*len(train_data[\"Merchant Name\"].unique())).set_index(train_data[\"Merchant Name\"].unique())\n",
        "\n",
        "nodes = {\"client\":train_data.card_id, \"merchant\":train_data[\"Merchant Name\"], \"transaction\":train_data.index}\n",
        "edges = [zip(train_data.card_id, train_data.index),zip(train_data[\"Merchant Name\"], train_data.index)]\n",
        "features = {\"transaction\": transaction_node_data, 'client': client_node_data, 'merchant': merchant_node_data}\n",
        "\n",
        "graph = GraphConstruction(nodes, edges, features)\n",
        "S = graph.get_stellargraph()\n",
        "print(S.info())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-16T21:09:47.819916Z",
          "iopub.execute_input": "2023-01-16T21:09:47.820745Z",
          "iopub.status.idle": "2023-01-16T21:09:49.98663Z",
          "shell.execute_reply.started": "2023-01-16T21:09:47.820707Z",
          "shell.execute_reply": "2023-01-16T21:09:49.985174Z"
        },
        "trusted": true,
        "id": "Ee1TQK9u1srG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#GraphSAGE parameters\n",
        "num_samples = [2,32]\n",
        "embedding_node_type = \"transaction\"\n",
        "\n",
        "hinsage = HinSAGE_Representation_Learner(embedding_size, num_samples, embedding_node_type)\n",
        "trained_hinsage_model, train_emb = hinsage.train_hinsage(S, list(train_data.index), train_data['Is Fraud?'], batch_size=5, epochs=10)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-16T21:09:49.988488Z",
          "iopub.execute_input": "2023-01-16T21:09:49.989169Z",
          "iopub.status.idle": "2023-01-16T21:22:25.952671Z",
          "shell.execute_reply.started": "2023-01-16T21:09:49.98913Z",
          "shell.execute_reply": "2023-01-16T21:22:25.951482Z"
        },
        "trusted": true,
        "id": "Aiw-p0fu1srG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bibliogtaphy :\n",
        "\n",
        "**Papers**\n",
        "\n",
        "Inductive Graph Representation Learning for fraud detection (paper)  : [Link](https://www.sciencedirect.com/science/article/abs/pii/S0957417421017449)\n",
        "\n",
        "Intelligent Financial Fraud Detection Practices: An\n",
        "Investigation : [Link](https://arxiv.org/ftp/arxiv/papers/1510/1510.07165.pdf)\n",
        "\n",
        "Modeling Relational Data with Graph Convolutional Networks : [Link](https://arxiv.org/pdf/1703.06103.pdf)\n",
        "\n",
        "For more papers check this github [link](https://github.com/benedekrozemberczki/awesome-fraud-detection-papers)\n",
        "\n",
        "**Library**\n",
        "\n",
        "Inductive-Graph-Representation-Learning-for-Fraud-Detection (library) : [Link](https://github.com/Charlesvandamme/Inductive-Graph-Representation-Learning-for-Fraud-Detection)\n",
        "\n",
        "**Dataset**\n",
        "\n",
        "IBM dataset :\n",
        "* [Link1](https://github.com/IBM/TabFormer) github\n",
        "* [Link2](https://ibm.ent.box.com/v/tabformer-data) IBM@Box\n",
        "* [Link3](https://www.kaggle.com/datasets/ealtman2019/credit-card-transactions) kaggle\n",
        "\n",
        "**Others**\n",
        "\n",
        "11 Categorical Encoders and Benchmark : [Link](https://www.kaggle.com/code/subinium/11-categorical-encoders-and-benchmark#1.-Label-Encoder-(LE),-Ordinary-Encoder(OE))\n",
        "\n",
        "StellarGraph : [Link](https://stellargraph.readthedocs.io/en/stable/README.html#example-gcn)\n",
        "\n",
        "NetworkX : [Link](https://networkx.org)"
      ],
      "metadata": {
        "id": "17lNWMYm1srG"
      }
    }
  ]
}